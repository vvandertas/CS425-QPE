{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sign table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1.,  1.],\n",
       "       [ 1., -1., -1.],\n",
       "       [-1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyDOE2 import *\n",
    "# Generate sign table for experiments using Plackett-Burman design\n",
    "sign_table = pbdesign(3)\n",
    "sign_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from calendar import timegm\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "import researchpy as rp\n",
    "\n",
    "date_format = \"%Y/%m/%d:%H:%M:%S\"\n",
    "\n",
    "# Takes a string containing date and time and converts it to epoch time\n",
    "def timestamp_converter(timestamp):\n",
    "    utc_time = time.strptime(timestamp, date_format)\n",
    "    return timegm(utc_time)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_service_and_arrival_times(experiment):\n",
    "    if isinstance(experiment, int):      \n",
    "        service_path ='data/service/exp' + str(experiment) + \"/run\" \n",
    "        arrivals_path ='data/arrivals/exp' + str(experiment) + \"/run\"\n",
    "    else:\n",
    "        service_path = 'data/service/' + str(experiment) + \"/run\" \n",
    "        arrivals_path = 'data/arrivals/' + str(experiment) + \"/run\"\n",
    "        \n",
    "    times = pd.DataFrame({}, columns = ['job', 'arrival_time', 'serivice_time'])\n",
    "    times_per_run = {}# pd.DataFrame({}, columns = ['job', 'arrival_time', 'serivice_time'])\n",
    "    run_times = []\n",
    "    for run in range(1,4):\n",
    "        # Load the arrivals and service time data for a single run for this experiment\n",
    "        temp_service = pd.read_csv(service_path + str(run) + '.csv',  delimiter=' ')\n",
    "        temp_arrivals = pd.read_csv(arrivals_path + str(run) + '.csv',  delimiter=' ')\n",
    "        \n",
    "        # Transform the date string values into epoch values\n",
    "        temp_arrivals['arrival_time'] = temp_arrivals['arrival_time'].apply(lambda x: timestamp_converter(x))\n",
    "            \n",
    "        # Compute the average runtimes for this run\n",
    "        run_times.append(np.mean(temp_service['end_time']-temp_arrivals['arrival_time']))\n",
    "        \n",
    "        # Merge the data into a single df\n",
    "        merged_temp = pd.merge(temp_arrivals, temp_service, on='job')\n",
    "        \n",
    "        times_per_run[str(experiment) + '-' + str(run)]=merged_temp\n",
    "        \n",
    "        # Concatenate the df to the results of previous runs \n",
    "        if times.empty:\n",
    "            times = merged_temp\n",
    "        else:\n",
    "            times = pd.concat([times, merged_temp])\n",
    "        \n",
    "    return times, run_times, times_per_run    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>service_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1571314170</td>\n",
       "      <td>139.008</td>\n",
       "      <td>1.571314e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1571314477</td>\n",
       "      <td>120.696</td>\n",
       "      <td>1.571315e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1571314598</td>\n",
       "      <td>121.408</td>\n",
       "      <td>1.571315e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1571314719</td>\n",
       "      <td>121.217</td>\n",
       "      <td>1.571315e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1571314840</td>\n",
       "      <td>121.023</td>\n",
       "      <td>1.571315e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1571314961</td>\n",
       "      <td>121.926</td>\n",
       "      <td>1.571315e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1571315083</td>\n",
       "      <td>120.992</td>\n",
       "      <td>1.571315e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1571315204</td>\n",
       "      <td>120.975</td>\n",
       "      <td>1.571315e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1571315325</td>\n",
       "      <td>121.279</td>\n",
       "      <td>1.571315e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1571315447</td>\n",
       "      <td>120.670</td>\n",
       "      <td>1.571316e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1571315567</td>\n",
       "      <td>119.856</td>\n",
       "      <td>1.571316e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1571315718</td>\n",
       "      <td>119.684</td>\n",
       "      <td>1.571316e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1571316226</td>\n",
       "      <td>120.241</td>\n",
       "      <td>1.571316e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>1571316467</td>\n",
       "      <td>120.013</td>\n",
       "      <td>1.571317e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1571316776</td>\n",
       "      <td>121.240</td>\n",
       "      <td>1.571317e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>1571316961</td>\n",
       "      <td>120.961</td>\n",
       "      <td>1.571317e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1571317082</td>\n",
       "      <td>119.999</td>\n",
       "      <td>1.571317e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>1571317316</td>\n",
       "      <td>119.761</td>\n",
       "      <td>1.571317e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>1571317485</td>\n",
       "      <td>120.927</td>\n",
       "      <td>1.571318e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    job  arrival_time  service_time      end_time\n",
       "0     0    1571314170       139.008  1.571314e+09\n",
       "1     1    1571314477       120.696  1.571315e+09\n",
       "2     2    1571314598       121.408  1.571315e+09\n",
       "3     3    1571314719       121.217  1.571315e+09\n",
       "4     4    1571314840       121.023  1.571315e+09\n",
       "5     5    1571314961       121.926  1.571315e+09\n",
       "6     6    1571315083       120.992  1.571315e+09\n",
       "7     7    1571315204       120.975  1.571315e+09\n",
       "8     8    1571315325       121.279  1.571315e+09\n",
       "9     9    1571315447       120.670  1.571316e+09\n",
       "10   10    1571315567       119.856  1.571316e+09\n",
       "11   11    1571315718       119.684  1.571316e+09\n",
       "12   12    1571316226       120.241  1.571316e+09\n",
       "13   13    1571316467       120.013  1.571317e+09\n",
       "14   14    1571316776       121.240  1.571317e+09\n",
       "15   15    1571316961       120.961  1.571317e+09\n",
       "16   16    1571317082       119.999  1.571317e+09\n",
       "17   17    1571317316       119.761  1.571317e+09\n",
       "18   18    1571317485       120.927  1.571318e+09"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collecting the timing data for all experiments\n",
    "all_timing_data = {}\n",
    "all_runtimes = []\n",
    "all_timing_data_per_run = {}\n",
    "\n",
    "for exp in range(1,5):\n",
    "    # Load the data, remove the job column and reset the row index\n",
    "    exp_times, exp_runtimes, exp_times_per_run = load_service_and_arrival_times(exp)\n",
    "    exp_times = exp_times.drop(columns = ['job']).reset_index(drop=True)\n",
    "    \n",
    "    # Compute and add the runtimes\n",
    "    exp_times['runtime']=exp_times['end_time']-exp_times['arrival_time']\n",
    "    \n",
    "    # Add the timing data for this experiment to all_timing_data\n",
    "    all_timing_data[exp] = exp_times\n",
    "    \n",
    "    # as well as the timing data per run\n",
    "    all_timing_data_per_run.update(exp_times_per_run)\n",
    "    \n",
    "    # and the avg runtimes to all_runtimes\n",
    "    all_runtimes.extend(exp_runtimes)\n",
    "    \n",
    "all_timing_data_per_run.get('1-1')\n",
    "#all_runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression model fit using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch has coefficient 36.411059957329535\n",
      "cores has coefficient -64.96256885567598\n",
      "batch_size has coefficient -2.5128532426916195\n"
     ]
    }
   ],
   "source": [
    "# Collecting the timing data for all experiments\n",
    "all_timing_data = {}\n",
    "all_runtimes = []\n",
    "\n",
    "epochs = [5, 20, 5, 20]\n",
    "cores = [4, 4, 8, 8]\n",
    "batch_sizes = [256, 64, 64, 256]\n",
    "\n",
    "for exp in range(1,5):\n",
    "    # Load the data, remove the job column and reset the row index\n",
    "    exp_times, exp_runtimes, exp_times_per_run = load_service_and_arrival_times(exp)\n",
    "    exp_times = exp_times.reset_index(drop=True)\n",
    "    \n",
    "    # Compute and add the runtimes\n",
    "    exp_times['runtime']=exp_times['end_time']-exp_times['arrival_time']\n",
    "    \n",
    "    # Add the timing data for this experiment to all_timing_data\n",
    "    all_timing_data[exp] = exp_times\n",
    "    \n",
    "    # and the avg runtimes to all_runtimes\n",
    "    all_runtimes.extend(exp_runtimes)\n",
    "\n",
    "    #add factor values to the dataframe\n",
    "    all_timing_data.get(exp)[\"epoch\"] = epochs[exp-1]\n",
    "    all_timing_data.get(exp)[\"cores\"] = cores[exp-1]\n",
    "    all_timing_data.get(exp)[\"batch_size\"] = batch_sizes[exp-1]\n",
    "\n",
    "    \n",
    "df = pd.DataFrame.from_dict(all_timing_data.get(1))\n",
    "for exp in range(2, 5):\n",
    "    df = df.append(pd.DataFrame.from_dict(all_timing_data.get(exp)))\n",
    "\n",
    "df = df.drop(columns=[\"job\", \"arrival_time\", \"service_time\", \"end_time\"])\n",
    "\n",
    "X = df.drop(columns=[\"runtime\"])\n",
    "y = df[\"runtime\"]\n",
    "\n",
    "clf = LinearRegression().fit(X, y)\n",
    "\n",
    "for col, coef in zip(X.columns, clf.coef_):\n",
    "    print(f\"{col} has coefficient {coef}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average runtime for baseline: 383.71768385392653\n"
     ]
    }
   ],
   "source": [
    "# Collect timing data for baseline runs\n",
    "baseline_times, baseline_avg_runtimes, baseline_times_per_run = load_service_and_arrival_times(\"baseline\")\n",
    "baseline_times = baseline_times.drop(columns = ['job']).reset_index(drop=True)\n",
    "\n",
    "# Compute and add the runtimes\n",
    "baseline_times['runtime']=baseline_times['end_time']-baseline_times['arrival_time']\n",
    "\n",
    "#add factor values to the dataframe\n",
    "baseline_times[\"epoch\"] = 10\n",
    "baseline_times[\"cores\"] = 6\n",
    "baseline_times[\"batch\"] = 128\n",
    "\n",
    "print(\"Average runtime for baseline: \" + str(np.average(baseline_avg_runtimes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average runtime for improved baseline: 172.26622689815989\n"
     ]
    }
   ],
   "source": [
    "# Collect timing data for baseline runs\n",
    "baseline_improved_times, baseline_improved_avg_runtimes, baseline_improved_times_per_run = load_service_and_arrival_times(\"improved-baseline\")\n",
    "#baseline_times = baseline_times.drop(columns = ['job']).reset_index(drop=True)\n",
    "\n",
    "# Compute and add the runtimes\n",
    "baseline_improved_times['runtime']=baseline_improved_times['end_time']-baseline_improved_times['arrival_time']\n",
    "\n",
    "#add factor values to the dataframe\n",
    "baseline_improved_times[\"epoch\"] = 10\n",
    "baseline_improved_times[\"cores\"] = 6\n",
    "baseline_improved_times[\"batch\"] = 512\n",
    "\n",
    "print(\"Average runtime for improved baseline: \" + str(np.average(baseline_improved_avg_runtimes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average jobs per experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1 avg jobs: 19.0\n",
      "Experiment 2 avg jobs: 3.0\n",
      "Experiment 3 avg jobs: 10.0\n",
      "Experiment 4 avg jobs: 8.333333333333334\n",
      "Baseline avg jobs: 9.0\n",
      "Baseline improved avg jobs: 19.0\n"
     ]
    }
   ],
   "source": [
    "for exp in range(1,5):\n",
    "    print(f\"Experiment {exp} avg jobs: {len(all_timing_data.get(exp))/3}\")\n",
    "    \n",
    "#Average jobs for baselines\n",
    "print(f\"Baseline avg jobs: \" + str((len(baseline_times[\"runtime\"])/3)))\n",
    "print(f\"Baseline improved avg jobs: \" + str((len(baseline_improved_times[\"runtime\"])/3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline vs. improved baseline T-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: 228.44555906383425, p2: 9.167919353383126e-117\n"
     ]
    }
   ],
   "source": [
    "t2, p2 = stats.ttest_ind(baseline_times[\"runtime\"],baseline_improved_times[\"runtime\"])\n",
    "print(f\"T: {t2}, p2: {p2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average runtime for experiment 1: 124.22859359205815\n",
      "Average runtime for experiment 2: 1152.8623155487908\n",
      "Average runtime for experiment 3: 346.8461407661438\n",
      "Average runtime for experiment 4: 410.5442175292969\n"
     ]
    }
   ],
   "source": [
    "# Compute the average runtimes\n",
    "avg_runtimes = {}\n",
    "for exp in range(1, 5):\n",
    "    average_runtime = np.average(np.array(all_timing_data[exp].runtime))\n",
    "    avg_runtimes[exp] = average_runtime\n",
    "    print(\"Average runtime for experiment \" + str(exp) + \": \" + str(average_runtime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for experiment 1: 0.891861403508772\n",
      "Average accuracy for experiment 2: 0.9598454545454547\n",
      "Average accuracy for experiment 3: 0.9434787878787879\n",
      "Average accuracy for experiment 4: 0.944562962962963\n"
     ]
    }
   ],
   "source": [
    "for exp in range(1,5):\n",
    "    accuracy_path ='data/accuracies/exp' + str(exp) +\".csv\" \n",
    "    accuracies = pd.read_csv(accuracy_path, header=None)\n",
    "    print(\"Average accuracy for experiment \" +  str(exp) + \": \"+ str(np.average(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for baseline: 0.94281\n"
     ]
    }
   ],
   "source": [
    "baseline_accuracy = pd.read_csv('data/accuracies/baseline.csv', header=None)\n",
    "print(\"Average accuracy for baseline: \" + str(np.average(baseline_accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for improved baseline: 0.8913315789473685\n"
     ]
    }
   ],
   "source": [
    "improved_baseline_accuracy = pd.read_csv('data/accuracies/improved-baseline.csv', header=None)\n",
    "print(\"Average accuracy for improved baseline: \" + str(np.average(improved_baseline_accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression model based on sign-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [ 1.  1.  1.]]\n",
      "[2034.4812674362897, 1092.3317987198857, -519.7005508454083, -964.9356451935796]\n",
      "\n",
      "Effect per factor: [508.62031685907243, 273.0829496799714, -129.92513771135208, -241.2339112983949]\n"
     ]
    }
   ],
   "source": [
    "# Create/solve regression model\n",
    "print(sign_table)\n",
    "\n",
    "y_mean = np.array(list(avg_runtimes.values()))\n",
    "regression_totals = [sum(avg_runtimes.values())]\n",
    "for i in range(sign_table.shape[1]):\n",
    "    regression_totals.append(sum(sign_table[:,i]*y_mean))\n",
    "\n",
    "print(regression_totals)\n",
    "\n",
    "# Calulate effect per factor\n",
    "effect = [x / 4 for x in regression_totals]\n",
    "print(\"\\nEffect per factor: \" + str(effect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-120.31695564919747"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def toNaturalVariable(obtained_value, min_value, max_value):\n",
    "    return obtained_value * ((min_value+max_value)/2) + (max_value-min_value)/2\n",
    "\n",
    "epochs = [5, 20]\n",
    "cores = [4, 8]\n",
    "batch_sizes = [64, 256]\n",
    "\n",
    "natural_epoch = toNaturalVariable(effect[3], 64, 256)\n",
    "natural_epoch/(64+256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>N</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "      <th>SE</th>\n",
       "      <th>95% Conf.</th>\n",
       "      <th>Interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Runtime</td>\n",
       "      <td>12.0</td>\n",
       "      <td>508.706567</td>\n",
       "      <td>404.330085</td>\n",
       "      <td>116.720042</td>\n",
       "      <td>251.807487</td>\n",
       "      <td>765.605647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Variable     N        Mean          SD          SE   95% Conf.    Interval\n",
       "0  Runtime  12.0  508.706567  404.330085  116.720042  251.807487  765.605647"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Runtime': np.array(all_runtimes),\n",
    "                   'Epoch': np.repeat(sign_table[:,0], 3),\n",
    "                   'Cores': np.repeat(sign_table[:,1], 3),\n",
    "                   'Batch': np.repeat(sign_table[:,2], 3)})\n",
    "\n",
    "rp.summary_cont(df['Runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=1.26751846331358, pvalue=0.2865263936107226)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.f_oneway(df['Runtime'][df['Cores'] == -1], \n",
    "             df['Runtime'][df['Cores'] == 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/veerle/.local/lib/python3.6/site-packages/scipy/stats/stats.py:1450: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=12\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Cores</td>\n",
       "      <td>2.022976e+05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.267518</td>\n",
       "      <td>0.286526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Residual</td>\n",
       "      <td>1.596013e+06</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sum_sq    df         F    PR(>F)\n",
       "Cores     2.022976e+05   1.0  1.267518  0.286526\n",
       "Residual  1.596013e+06  10.0       NaN       NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# ANOVA for Cores\n",
    "rp.summary_cont(df.groupby(['Cores']))['Runtime']\n",
    "cores_model = ols('Runtime ~ Cores', data=df).fit()\n",
    "cores_model.summary()\n",
    "\n",
    "aov_table = sm.stats.anova_lm(cores_model, typ=2)\n",
    "aov_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/veerle/.local/lib/python3.6/site-packages/scipy/stats/stats.py:1450: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=12\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Batch</td>\n",
       "      <td>6.978263e+05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.341082</td>\n",
       "      <td>0.030484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Residual</td>\n",
       "      <td>1.100485e+06</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sum_sq    df         F    PR(>F)\n",
       "Batch     6.978263e+05   1.0  6.341082  0.030484\n",
       "Residual  1.100485e+06  10.0       NaN       NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANOVA for Batch size\n",
    "rp.summary_cont(df.groupby(['Batch']))['Runtime']\n",
    "batch_model = ols('Runtime ~ Batch', data=df).fit()\n",
    "batch_model.summary()\n",
    "\n",
    "aov_table = sm.stats.anova_lm(batch_model, typ=2)\n",
    "aov_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/veerle/.local/lib/python3.6/site-packages/scipy/stats/stats.py:1450: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=12\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Epoch</td>\n",
       "      <td>895456.942631</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.91807</td>\n",
       "      <td>0.010345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Residual</td>\n",
       "      <td>902854.054602</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 sum_sq    df        F    PR(>F)\n",
       "Epoch     895456.942631   1.0  9.91807  0.010345\n",
       "Residual  902854.054602  10.0      NaN       NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANOVA for Training Epoch size\n",
    "epoch_model = ols('Runtime ~ Epoch', data=df).fit()\n",
    "epoch_model.summary()\n",
    "\n",
    "aov_table = sm.stats.anova_lm(epoch_model, typ=2)\n",
    "aov_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/veerle/.local/lib/python3.6/site-packages/scipy/stats/stats.py:1450: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=12\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Runtime</td>     <th>  R-squared:         </th> <td>   0.998</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.998</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1754.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 28 Oct 2019</td> <th>  Prob (F-statistic):</th> <td>1.31e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:47:46</td>     <th>  Log-Likelihood:    </th> <td> -49.590</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    12</td>      <th>  AIC:               </th> <td>   107.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     8</td>      <th>  BIC:               </th> <td>   109.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  508.7066</td> <td>    5.333</td> <td>   95.393</td> <td> 0.000</td> <td>  496.409</td> <td>  521.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Batch</th>     <td> -241.1477</td> <td>    5.333</td> <td>  -45.220</td> <td> 0.000</td> <td> -253.445</td> <td> -228.850</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cores</th>     <td> -129.8389</td> <td>    5.333</td> <td>  -24.347</td> <td> 0.000</td> <td> -142.136</td> <td> -117.542</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Epoch</th>     <td>  273.1692</td> <td>    5.333</td> <td>   51.225</td> <td> 0.000</td> <td>  260.872</td> <td>  285.467</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 6.776</td> <th>  Durbin-Watson:     </th> <td>   3.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.034</td> <th>  Jarque-Bera (JB):  </th> <td>   3.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.398</td> <th>  Prob(JB):          </th> <td>   0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.467</td> <th>  Cond. No.          </th> <td>    1.00</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                Runtime   R-squared:                       0.998\n",
       "Model:                            OLS   Adj. R-squared:                  0.998\n",
       "Method:                 Least Squares   F-statistic:                     1754.\n",
       "Date:                Mon, 28 Oct 2019   Prob (F-statistic):           1.31e-11\n",
       "Time:                        08:47:46   Log-Likelihood:                -49.590\n",
       "No. Observations:                  12   AIC:                             107.2\n",
       "Df Residuals:                       8   BIC:                             109.1\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    508.7066      5.333     95.393      0.000     496.409     521.004\n",
       "Batch       -241.1477      5.333    -45.220      0.000    -253.445    -228.850\n",
       "Cores       -129.8389      5.333    -24.347      0.000    -142.136    -117.542\n",
       "Epoch        273.1692      5.333     51.225      0.000     260.872     285.467\n",
       "==============================================================================\n",
       "Omnibus:                        6.776   Durbin-Watson:                   3.042\n",
       "Prob(Omnibus):                  0.034   Jarque-Bera (JB):                3.360\n",
       "Skew:                           0.398   Prob(JB):                        0.186\n",
       "Kurtosis:                       5.467   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANOVA for all factors\n",
    "all_factor_model = ols('Runtime ~  Batch+Cores+Epoch', data=df).fit()\n",
    "all_factor_model.summary()\n",
    "\n",
    "# aov_table = sm.stats.anova_lm(interaction_model, typ=2)\n",
    "# aov_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1608.3829332433963 3.7876269235115543e-11 True\n"
     ]
    }
   ],
   "source": [
    "overall_model = ols('Runtime ~ Batch*Cores*Epoch', data=df).fit()\n",
    "baseline_model = ols('runtime ~batch*cores*epoch', data=baseline_times).fit()\n",
    "improved_baseline_model = ols('runtime ~batch*cores*epoch', data=baseline_improved_times).fit()\n",
    "\n",
    "f_val, p_val, _ = overall_model.compare_f_test(batch_model)\n",
    "print(f_val, p_val, p_val<0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G/G/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate G/G/1 queue\n",
    "def queuing_simulation(data):\n",
    "    N = len(data)\n",
    "    At = np.array(data.arrival_time)\n",
    "\n",
    "    S = np.zeros(N) # -> Service start time\n",
    "    C = np.zeros(N) # -> Complete time\n",
    "    W = np.zeros(N) # -> response time of job i (waiting time) \n",
    "\n",
    "    S[0] = At[0]\n",
    "    C[0] = S[0] + data.service_time[0]\n",
    "    W[0] = C[0] - At[0]\n",
    "\n",
    "    for i in range(1, N):\n",
    "        S[i] = max(C[i-1], At[i])\n",
    "        C[i] = S[i] + data.service_time[i]\n",
    "        W[i] = C[i] - At[i]\n",
    "\n",
    "    return np.average(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp 1: 121.88989477408559\n",
      "Exp 2: 1148.0766666730244\n",
      "Exp 3: 346.6546999454498\n",
      "Exp 4: 416.1967500448227\n",
      "\n",
      "Baseline: 382.3243333498637\n",
      "Baseline improved: 173.73405265808105\n"
     ]
    }
   ],
   "source": [
    "# Run the G/G/1 queuing simulation for all experiments, using only the first run\n",
    "for i in range(1,5):\n",
    "    key = str(i) + '-1'\n",
    "    print(f\"Exp {i}: {queuing_simulation(all_timing_data_per_run.get(key))}\")\n",
    "    \n",
    "print(f\"\\nBaseline: {queuing_simulation(baseline_times_per_run.get('baseline-1'))}\")\n",
    "print(f\"Baseline improved: {queuing_simulation(baseline_improved_times_per_run.get('improved-baseline-1'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'improved-baseline-1':     job  arrival_time  service_time      end_time\n",
       " 0     0    1571832868       192.507  1.571833e+09\n",
       " 1     1    1571833175       172.454  1.571833e+09\n",
       " 2     2    1571833348       172.943  1.571834e+09\n",
       " 3     3    1571833521       169.337  1.571834e+09\n",
       " 4     4    1571833690       176.415  1.571834e+09\n",
       " 5     5    1571833866       171.775  1.571834e+09\n",
       " 6     6    1571834038       173.522  1.571834e+09\n",
       " 7     7    1571834212       169.170  1.571834e+09\n",
       " 8     8    1571834381       171.934  1.571835e+09\n",
       " 9     9    1571834553       171.848  1.571835e+09\n",
       " 10   10    1571834725       173.006  1.571835e+09\n",
       " 11   11    1571834898       172.782  1.571835e+09\n",
       " 12   12    1571835071       174.316  1.571835e+09\n",
       " 13   13    1571835245       173.258  1.571835e+09\n",
       " 14   14    1571835474       173.050  1.571836e+09\n",
       " 15   15    1571835659       175.623  1.571836e+09\n",
       " 16   16    1571835835       172.829  1.571836e+09\n",
       " 17   17    1571836014       171.607  1.571836e+09\n",
       " 18   18    1571836186       170.210  1.571836e+09,\n",
       " 'improved-baseline-2':     job  arrival_time  service_time      end_time\n",
       " 0     0    1571836668       175.055  1.571837e+09\n",
       " 1     1    1571836975       173.056  1.571837e+09\n",
       " 2     2    1571837148       171.944  1.571837e+09\n",
       " 3     3    1571837320       170.831  1.571837e+09\n",
       " 4     4    1571837491       174.425  1.571838e+09\n",
       " 5     5    1571837665       171.342  1.571838e+09\n",
       " 6     6    1571837837       176.810  1.571838e+09\n",
       " 7     7    1571838013       173.886  1.571838e+09\n",
       " 8     8    1571838187       174.574  1.571838e+09\n",
       " 9     9    1571838362       176.594  1.571839e+09\n",
       " 10   10    1571838539       176.485  1.571839e+09\n",
       " 11   11    1571838715       170.140  1.571839e+09\n",
       " 12   12    1571838885       169.172  1.571839e+09\n",
       " 13   13    1571839054       171.147  1.571839e+09\n",
       " 14   14    1571839274       178.337  1.571839e+09\n",
       " 15   15    1571839459       176.698  1.571840e+09\n",
       " 16   16    1571839636       166.589  1.571840e+09\n",
       " 17   17    1571839814       166.605  1.571840e+09\n",
       " 18   18    1571839983       166.770  1.571840e+09,\n",
       " 'improved-baseline-3':     job  arrival_time  service_time      end_time\n",
       " 0     0    1571840468       169.702  1.571841e+09\n",
       " 1     1    1571840775       167.396  1.571841e+09\n",
       " 2     2    1571840942       168.426  1.571841e+09\n",
       " 3     3    1571841111       169.329  1.571841e+09\n",
       " 4     4    1571841280       169.334  1.571841e+09\n",
       " 5     5    1571841450       170.691  1.571842e+09\n",
       " 6     6    1571841620       168.300  1.571842e+09\n",
       " 7     7    1571841789       166.652  1.571842e+09\n",
       " 8     8    1571841955       167.909  1.571842e+09\n",
       " 9     9    1571842123       167.968  1.571842e+09\n",
       " 10   10    1571842291       168.873  1.571842e+09\n",
       " 11   11    1571842460       171.291  1.571843e+09\n",
       " 12   12    1571842631       170.518  1.571843e+09\n",
       " 13   13    1571842802       168.907  1.571843e+09\n",
       " 14   14    1571843074       169.521  1.571843e+09\n",
       " 15   15    1571843259       167.242  1.571843e+09\n",
       " 16   16    1571843426       168.462  1.571844e+09\n",
       " 17   17    1571843614       169.926  1.571844e+09\n",
       " 18   18    1571843784       168.294  1.571844e+09}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_timing_data_per_run.get('1-1').arrival_time\n",
    "baseline_improved_times_per_run\n",
    "# print(queuing_simulation(all_timing_data.get('1-1')))"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
