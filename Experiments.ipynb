{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sign table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1.,  1.],\n",
       "       [ 1., -1., -1.],\n",
       "       [-1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyDOE2 import *\n",
    "# Generate sign table for experiments using Plackett-Burman design\n",
    "sign_table = pbdesign(3)\n",
    "sign_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from calendar import timegm\n",
    "from datetime import datetime\n",
    "\n",
    "date_format = \"%Y/%m/%d:%H:%M:%S\"\n",
    "\n",
    "# Takes a string containing date and time and converts it to epoch time\n",
    "def timestamp_converter(timestamp):\n",
    "    utc_time = time.strptime(timestamp, date_format)\n",
    "    return timegm(utc_time)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_service_and_arrival_times(experiment):\n",
    "    service_path ='data/service/exp' + str(experiment) + \"/run\" \n",
    "    arrivals_path ='data/arrivals/exp' + str(experiment) + \"/run\"\n",
    "\n",
    "    times = pd.DataFrame({}, columns = ['job', 'arrival_time', 'serivice_time'])\n",
    "    for run in range(1,4):\n",
    "        # Load the arrivals and service time data for a single run for this experiment\n",
    "        temp_service = pd.read_csv(service_path + str(run) + '.csv',  delimiter=' ')\n",
    "        temp_arrivals = pd.read_csv(arrivals_path + str(run) + '.csv',  delimiter=' ')\n",
    "        \n",
    "        # Transform the date string values into epoch values\n",
    "        temp_arrivals['arrival_time'] = temp_arrivals['arrival_time'].apply(lambda x: timestamp_converter(x))\n",
    "        \n",
    "        # Merge the data into a single df\n",
    "        merged_temp = pd.merge(temp_arrivals, temp_service, on='job')\n",
    "        \n",
    "        # Concatenate the df to the results of previous runs \n",
    "        if times.empty:\n",
    "            times = merged_temp\n",
    "        else:\n",
    "            times = pd.concat([times, merged_temp])\n",
    "        \n",
    "    return times    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting the timing data for all experiments\n",
    "all_timing_data = {}\n",
    "for exp in range(1,5):\n",
    "    # Load the data, remove the job column and reset the row index\n",
    "    exp_times = load_service_and_arrival_times(exp).drop(columns = ['job']).reset_index(drop=True)\n",
    "    \n",
    "    # Compute and add the runtimes\n",
    "    exp_times['runtime']=exp_times['end_time']-exp_times['arrival_time']\n",
    "    \n",
    "    # Add the data for this experiment to all_timing_data\n",
    "    all_timing_data[exp] = exp_times\n",
    "    \n",
    "# all_timing_data.get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average runtime for experiment 1: 124.22859359205815\n",
      "Average runtime for experiment 2: 1152.8623155487908\n",
      "Average runtime for experiment 3: 346.8461407661438\n",
      "Average runtime for experiment 4: 410.5442175292969\n"
     ]
    }
   ],
   "source": [
    "# Compute the average runtimes\n",
    "avg_runtimes = {}\n",
    "for exp in range(1, 5):\n",
    "    average_runtime = np.average(np.array(all_timing_data[exp].runtime))\n",
    "    avg_runtimes[exp] = average_runtime\n",
    "    print(\"Average runtime for experiment \" + str(exp) + \": \" + str(average_runtime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for experiment 1: 0.891861403508772\n",
      "Average accuracy for experiment 2: 0.9598454545454547\n",
      "Average accuracy for experiment 3: 0.9434787878787879\n",
      "Average accuracy for experiment 4: 0.944562962962963\n"
     ]
    }
   ],
   "source": [
    "for exp in range(1,5):\n",
    "    accuracy_path ='data/accuracies/exp' + str(exp) +\".csv\" \n",
    "    accuracies = pd.read_csv(accuracy_path, header=None)\n",
    "    print(\"Average accuracy for experiment \" +  str(exp) + \": \"+ str(np.average(accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [ 1.  1.  1.]]\n",
      "[2034.4812674362897, 1092.3317987198857, -519.7005508454083, -964.9356451935796]\n",
      "\n",
      "Effect per factor: [508.62031685907243, 273.0829496799714, -129.92513771135208, -241.2339112983949]\n"
     ]
    }
   ],
   "source": [
    "# Create/solve regresion modal\n",
    "print(sign_table)\n",
    "\n",
    "y_mean = np.array(list(avg_runtimes.values()))\n",
    "regression_totals = [sum(avg_runtimes.values())]\n",
    "for i in range(sign_table.shape[1]):\n",
    "    regression_totals.append(sum(sign_table[:,i]*y_mean))\n",
    "\n",
    "print(regression_totals)\n",
    "\n",
    "# Calulate effect per factor\n",
    "effect = [x / 4 for x in regression_totals]\n",
    "print(\"\\nEffect per factor: \" + str(effect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G/G/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate G/G/1 queue\n",
    "def queuing_simulation(data):\n",
    "    N = len(data)\n",
    "    At = data.arrival_time\n",
    "\n",
    "    S = np.zeros(N) # -> Service start time\n",
    "    C = np.zeros(N) # -> Complete time\n",
    "    W = np.zeros(N) # -> response time of job i (waiting time) \n",
    "\n",
    "    S[0] = At[0]\n",
    "    C[0] = S[0] + data.service_time[0]\n",
    "    W[0] = C[0] - At[0]\n",
    "\n",
    "    for i in range(1, N):\n",
    "        S[i] = max(C[i-1], At[i])\n",
    "        C[i] = S[i] + data.service_time[i]\n",
    "        W[i] = C[i] - At[i]\n",
    "\n",
    "#     print(\"Average simulated run time: \" + str(np.average(W)))\n",
    "    return np.average(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123.94045613941394\n",
      "1152.5422222879197\n",
      "346.7322332938512\n",
      "410.3491999912262\n"
     ]
    }
   ],
   "source": [
    "# Run the G/G/1 queuing simulation for all experiments\n",
    "for i in range(1,5):\n",
    "    # avrg simulated runtime\n",
    "    print(queuing_simulation(all_timing_data.get(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO: Compare simulated averages to actual averages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
