2019-10-17 18:04:08 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-17 18:04:08 INFO  SparkContext:54 - Running Spark version 2.3.1
2019-10-17 18:04:09 INFO  SparkContext:54 - Submitted application: lenet5
2019-10-17 18:04:09 INFO  SecurityManager:54 - Changing view acls to: ubuntu
2019-10-17 18:04:09 INFO  SecurityManager:54 - Changing modify acls to: ubuntu
2019-10-17 18:04:09 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-10-17 18:04:09 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-10-17 18:04:09 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ubuntu); groups with view permissions: Set(); users  with modify permissions: Set(ubuntu); groups with modify permissions: Set()
2019-10-17 18:04:09 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 39063.
2019-10-17 18:04:09 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-10-17 18:04:09 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-10-17 18:04:09 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-10-17 18:04:09 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-10-17 18:04:09 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-083763ce-93ce-4fd3-a8da-b40391dfd84d
2019-10-17 18:04:09 INFO  MemoryStore:54 - MemoryStore started with capacity 413.9 MB
2019-10-17 18:04:09 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-10-17 18:04:09 INFO  log:192 - Logging initialized @3702ms
2019-10-17 18:04:10 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-10-17 18:04:10 INFO  Server:414 - Started @3888ms
2019-10-17 18:04:10 INFO  AbstractConnector:278 - Started ServerConnector@391b67e5{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-10-17 18:04:10 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@347610b2{/jobs,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@64eade6{/jobs/json,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cb1a65c{/jobs/job,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3e40253b{/jobs/job/json,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d929e88{/stages,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3ce04220{/stages/json,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@26e175c2{/stages/stage,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7e47f5cb{/stages/stage/json,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@53a5c0a4{/stages/pool,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@759ae63d{/stages/pool/json,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77650ba8{/storage,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@364d5122{/storage/json,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b9017af{/storage/rdd,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6999bbee{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@367ed53e{/environment,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ae65692{/environment/json,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2100190e{/executors,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@562800b{/executors/json,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@457562bc{/executors/threadDump,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1d7ffe46{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c165c8e{/static,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4dfa24a4{/,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b8e7f6c{/api,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@36f93cae{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b78e82{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-10-17 18:04:10 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://bigdl-master.europe-west4-a.c.able-yew-254809.internal:4040
2019-10-17 18:04:10 INFO  SparkContext:54 - Added JAR file:///home/f1r3flyp1l0t/bd/spark/lib/bigdl-SPARK_2.3-0.8.0-jar-with-dependencies.jar at spark://bigdl-master.europe-west4-a.c.able-yew-254809.internal:39063/jars/bigdl-SPARK_2.3-0.8.0-jar-with-dependencies.jar with timestamp 1571335450465
2019-10-17 18:04:10 INFO  SparkContext:54 - Added file file:/home/f1r3flyp1l0t/bd/codes/lenet5.py at spark://bigdl-master.europe-west4-a.c.able-yew-254809.internal:39063/files/lenet5.py with timestamp 1571335450531
2019-10-17 18:04:10 INFO  Utils:54 - Copying /home/f1r3flyp1l0t/bd/codes/lenet5.py to /tmp/spark-2ec44bfb-f565-441e-9708-38a0009f46da/userFiles-8457ca73-d03d-475a-bb0a-91296d41f29c/lenet5.py
2019-10-17 18:04:10 INFO  SparkContext:54 - Added file file:///home/f1r3flyp1l0t/bd/spark/lib/bigdl-0.8.0-python-api.zip at spark://bigdl-master.europe-west4-a.c.able-yew-254809.internal:39063/files/bigdl-0.8.0-python-api.zip with timestamp 1571335450558
2019-10-17 18:04:10 INFO  Utils:54 - Copying /home/f1r3flyp1l0t/bd/spark/lib/bigdl-0.8.0-python-api.zip to /tmp/spark-2ec44bfb-f565-441e-9708-38a0009f46da/userFiles-8457ca73-d03d-475a-bb0a-91296d41f29c/bigdl-0.8.0-python-api.zip
2019-10-17 18:04:10 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://10.164.0.2:7077...
2019-10-17 18:04:10 INFO  TransportClientFactory:267 - Successfully created connection to /10.164.0.2:7077 after 58 ms (0 ms spent in bootstraps)
2019-10-17 18:04:11 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20191017180411-0060
2019-10-17 18:04:11 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20191017180411-0060/0 on worker-20191017114318-10.164.0.4-42945 (10.164.0.4:42945) with 4 core(s)
2019-10-17 18:04:11 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20191017180411-0060/0 on hostPort 10.164.0.4:42945 with 4 core(s), 12.0 GB RAM
2019-10-17 18:04:11 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20191017180411-0060/1 on worker-20191017114414-10.164.0.5-44255 (10.164.0.5:44255) with 4 core(s)
2019-10-17 18:04:11 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20191017180411-0060/1 on hostPort 10.164.0.5:44255 with 4 core(s), 12.0 GB RAM
2019-10-17 18:04:11 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45235.
2019-10-17 18:04:11 INFO  NettyBlockTransferService:54 - Server created on bigdl-master.europe-west4-a.c.able-yew-254809.internal:45235
2019-10-17 18:04:11 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-10-17 18:04:11 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20191017180411-0060/0 is now RUNNING
2019-10-17 18:04:11 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20191017180411-0060/1 is now RUNNING
2019-10-17 18:04:11 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, bigdl-master.europe-west4-a.c.able-yew-254809.internal, 45235, None)
2019-10-17 18:04:11 INFO  BlockManagerMasterEndpoint:54 - Registering block manager bigdl-master.europe-west4-a.c.able-yew-254809.internal:45235 with 413.9 MB RAM, BlockManagerId(driver, bigdl-master.europe-west4-a.c.able-yew-254809.internal, 45235, None)
2019-10-17 18:04:11 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, bigdl-master.europe-west4-a.c.able-yew-254809.internal, 45235, None)
2019-10-17 18:04:11 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, bigdl-master.europe-west4-a.c.able-yew-254809.internal, 45235, None)
2019-10-17 18:04:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@729820ea{/metrics/json,null,AVAILABLE,@Spark}
2019-10-17 18:04:12 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.164.0.4:39778) with ID 0
2019-10-17 18:04:12 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.164.0.5:43294) with ID 1
2019-10-17 18:04:13 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 1.0
2019-10-17 18:04:13 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.164.0.4:33895 with 6.2 GB RAM, BlockManagerId(0, 10.164.0.4, 33895, None)
2019-10-17 18:04:13 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.164.0.5:35825 with 6.2 GB RAM, BlockManagerId(1, 10.164.0.5, 35825, None)
2019-10-17 18:04:13 INFO  Engine$:112 - Auto detect executor number and executor cores number
2019-10-17 18:04:13 INFO  Engine$:114 - Executor number is 2 and executor cores number is 4
2019-10-17 18:04:13 INFO  ThreadPool$:95 - Set mkl threads to 1 on thread 17
2019-10-17 18:04:13 INFO  Engine$:402 - Find existing spark context. Checking the spark conf...
cls.getname: com.intel.analytics.bigdl.python.api.Sample
BigDLBasePickler registering: bigdl.util.common  Sample
cls.getname: com.intel.analytics.bigdl.python.api.EvaluatedResult
BigDLBasePickler registering: bigdl.util.common  EvaluatedResult
cls.getname: com.intel.analytics.bigdl.python.api.JTensor
BigDLBasePickler registering: bigdl.util.common  JTensor
cls.getname: com.intel.analytics.bigdl.python.api.JActivity
BigDLBasePickler registering: bigdl.util.common  JActivity
0.01
('Extracting', '/tmp/mnist/train-images-idx3-ubyte.gz')
('Extracting', '/tmp/mnist/train-labels-idx1-ubyte.gz')
('Extracting', '/tmp/mnist/t10k-images-idx3-ubyte.gz')
('Extracting', '/tmp/mnist/t10k-labels-idx1-ubyte.gz')
creating: createSequential
creating: createReshape
creating: createSpatialConvolution
creating: createTanh
creating: createSpatialMaxPooling
creating: createSpatialConvolution
creating: createTanh
creating: createSpatialMaxPooling
creating: createReshape
creating: createLinear
creating: createTanh
creating: createLinear
creating: createLogSoftMax
creating: createClassNLLCriterion
creating: createDefault
creating: createSGD
creating: createMaxEpoch
creating: createDistriOptimizer
disableCheckSingleton is deprecated. Please use bigdl.check.singleton instead
creating: createEveryEpoch
creating: createTop1Accuracy
creating: createEveryEpoch
2019-10-17 18:04:16 INFO  DistriOptimizer$:784 - caching training rdd ...
2019-10-17 18:04:24 INFO  DistriOptimizer$:624 - Cache thread models...
2019-10-17 18:04:25 INFO  DistriOptimizer$:626 - Cache thread models... done
2019-10-17 18:04:25 INFO  DistriOptimizer$:154 - Count dataset
2019-10-17 18:04:25 INFO  DistriOptimizer$:158 - Count dataset complete. Time elapsed: 0.213785574s
2019-10-17 18:04:25 INFO  DistriOptimizer$:166 - config  {
	computeThresholdbatchSize: 100
	maxDropPercentage: 0.0
	warmupIterationNum: 200
	isLayerwiseScaled: false
	dropPercentage: 0.0
 }
2019-10-17 18:04:25 INFO  DistriOptimizer$:170 - Shuffle data
2019-10-17 18:04:25 INFO  DistriOptimizer$:173 - Shuffle data complete. Takes 0.036704661s
2019-10-17 18:04:26 INFO  DistriOptimizer$:408 - [Epoch 1 256/60000][Iteration 1][Wall Clock 0.649021897s] Trained 256 records in 0.649021897 seconds. Throughput is 394.43967 records/second. Loss is 2.331794. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.01. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:26 INFO  DistriOptimizer$:408 - [Epoch 1 512/60000][Iteration 2][Wall Clock 0.929714281s] Trained 256 records in 0.280692384 seconds. Throughput is 912.0304 records/second. Loss is 2.3246121. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009998000399920017. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:26 INFO  DistriOptimizer$:408 - [Epoch 1 768/60000][Iteration 3][Wall Clock 1.141520005s] Trained 256 records in 0.211805724 seconds. Throughput is 1208.6548 records/second. Loss is 2.3268023. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009996001599360257. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:26 INFO  DistriOptimizer$:408 - [Epoch 1 1024/60000][Iteration 4][Wall Clock 1.403653188s] Trained 256 records in 0.262133183 seconds. Throughput is 976.6028 records/second. Loss is 2.327307. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009994003597841297. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:27 INFO  DistriOptimizer$:408 - [Epoch 1 1280/60000][Iteration 5][Wall Clock 1.59076658s] Trained 256 records in 0.187113392 seconds. Throughput is 1368.1544 records/second. Loss is 2.326136. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009992006394884094. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:27 INFO  DistriOptimizer$:408 - [Epoch 1 1536/60000][Iteration 6][Wall Clock 1.844420926s] Trained 256 records in 0.253654346 seconds. Throughput is 1009.2474 records/second. Loss is 2.3249412. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009990009990009992. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:27 INFO  DistriOptimizer$:408 - [Epoch 1 1792/60000][Iteration 7][Wall Clock 2.023921222s] Trained 256 records in 0.179500296 seconds. Throughput is 1426.1815 records/second. Loss is 2.3151765. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.00998801438274071. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:27 INFO  DistriOptimizer$:408 - [Epoch 1 2048/60000][Iteration 8][Wall Clock 2.188446551s] Trained 256 records in 0.164525329 seconds. Throughput is 1555.9915 records/second. Loss is 2.3237371. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009986019572598362. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:27 INFO  DistriOptimizer$:408 - [Epoch 1 2304/60000][Iteration 9][Wall Clock 2.367835903s] Trained 256 records in 0.179389352 seconds. Throughput is 1427.0635 records/second. Loss is 2.3179646. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009984025559105431. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:28 INFO  DistriOptimizer$:408 - [Epoch 1 2560/60000][Iteration 10][Wall Clock 2.532524354s] Trained 256 records in 0.164688451 seconds. Throughput is 1554.4502 records/second. Loss is 2.3172724. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009982032341784788. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:28 INFO  DistriOptimizer$:408 - [Epoch 1 2816/60000][Iteration 11][Wall Clock 2.747517267s] Trained 256 records in 0.214992913 seconds. Throughput is 1190.7369 records/second. Loss is 2.3188763. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.00998003992015968. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:28 INFO  DistriOptimizer$:408 - [Epoch 1 3072/60000][Iteration 12][Wall Clock 2.900885126s] Trained 256 records in 0.153367859 seconds. Throughput is 1669.1893 records/second. Loss is 2.334382. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009978048293753742. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:28 INFO  DistriOptimizer$:408 - [Epoch 1 3328/60000][Iteration 13][Wall Clock 3.062436223s] Trained 256 records in 0.161551097 seconds. Throughput is 1584.638 records/second. Loss is 2.3208618. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009976057462090982. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:28 INFO  DistriOptimizer$:408 - [Epoch 1 3584/60000][Iteration 14][Wall Clock 3.203454072s] Trained 256 records in 0.141017849 seconds. Throughput is 1815.3729 records/second. Loss is 2.3142273. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009974067424695792. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:28 INFO  DistriOptimizer$:408 - [Epoch 1 3840/60000][Iteration 15][Wall Clock 3.351551249s] Trained 256 records in 0.148097177 seconds. Throughput is 1728.5947 records/second. Loss is 2.3125472. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009972078181092942. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:29 INFO  DistriOptimizer$:408 - [Epoch 1 4096/60000][Iteration 16][Wall Clock 3.552820304s] Trained 256 records in 0.201269055 seconds. Throughput is 1271.9292 records/second. Loss is 2.3129556. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009970089730807579. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:29 INFO  DistriOptimizer$:408 - [Epoch 1 4352/60000][Iteration 17][Wall Clock 3.71532306s] Trained 256 records in 0.162502756 seconds. Throughput is 1575.3579 records/second. Loss is 2.3299446. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.00996810207336523. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:29 INFO  DistriOptimizer$:408 - [Epoch 1 4608/60000][Iteration 18][Wall Clock 3.865539922s] Trained 256 records in 0.150216862 seconds. Throughput is 1704.2028 records/second. Loss is 2.3157768. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009966115208291807. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:29 INFO  DistriOptimizer$:408 - [Epoch 1 4864/60000][Iteration 19][Wall Clock 3.999386951s] Trained 256 records in 0.133847029 seconds. Throughput is 1912.6312 records/second. Loss is 2.3265076. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.00996412913511359. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:29 INFO  DistriOptimizer$:408 - [Epoch 1 5120/60000][Iteration 20][Wall Clock 4.135565649s] Trained 256 records in 0.136178698 seconds. Throughput is 1879.8828 records/second. Loss is 2.2888412. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009962143853357242. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:29 INFO  DistriOptimizer$:408 - [Epoch 1 5376/60000][Iteration 21][Wall Clock 4.314085382s] Trained 256 records in 0.178519733 seconds. Throughput is 1434.0153 records/second. Loss is 2.3111703. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.0099601593625498. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:30 INFO  DistriOptimizer$:408 - [Epoch 1 5632/60000][Iteration 22][Wall Clock 4.442627296s] Trained 256 records in 0.128541914 seconds. Throughput is 1991.5682 records/second. Loss is 2.3138802. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009958175662218682. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:30 INFO  DistriOptimizer$:408 - [Epoch 1 5888/60000][Iteration 23][Wall Clock 4.58312867s] Trained 256 records in 0.140501374 seconds. Throughput is 1822.0461 records/second. Loss is 2.302473. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009956192751891677. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:30 INFO  DistriOptimizer$:408 - [Epoch 1 6144/60000][Iteration 24][Wall Clock 4.733433472s] Trained 256 records in 0.150304802 seconds. Throughput is 1703.2057 records/second. Loss is 2.3182433. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009954210631096954. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:30 INFO  DistriOptimizer$:408 - [Epoch 1 6400/60000][Iteration 25][Wall Clock 4.869578177s] Trained 256 records in 0.136144705 seconds. Throughput is 1880.3523 records/second. Loss is 2.3129416. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009952229299363059. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:30 INFO  DistriOptimizer$:408 - [Epoch 1 6656/60000][Iteration 26][Wall Clock 5.057282958s] Trained 256 records in 0.187704781 seconds. Throughput is 1363.8438 records/second. Loss is 2.2989223. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009950248756218907. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:30 INFO  DistriOptimizer$:408 - [Epoch 1 6912/60000][Iteration 27][Wall Clock 5.184360468s] Trained 256 records in 0.12707751 seconds. Throughput is 2014.5187 records/second. Loss is 2.3115134. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.00994826900119379. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:30 INFO  DistriOptimizer$:408 - [Epoch 1 7168/60000][Iteration 28][Wall Clock 5.309658888s] Trained 256 records in 0.12529842 seconds. Throughput is 2043.1222 records/second. Loss is 2.309567. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009946290033817386. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:31 INFO  DistriOptimizer$:408 - [Epoch 1 7424/60000][Iteration 29][Wall Clock 5.445196929s] Trained 256 records in 0.135538041 seconds. Throughput is 1888.7687 records/second. Loss is 2.3013465. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.00994431185361973. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:31 INFO  DistriOptimizer$:408 - [Epoch 1 7680/60000][Iteration 30][Wall Clock 5.581243173s] Trained 256 records in 0.136046244 seconds. Throughput is 1881.7131 records/second. Loss is 2.3009412. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.00994233446013124. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:31 INFO  DistriOptimizer$:408 - [Epoch 1 7936/60000][Iteration 31][Wall Clock 5.742184731s] Trained 256 records in 0.160941558 seconds. Throughput is 1590.6395 records/second. Loss is 2.3012674. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009940357852882704. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:31 INFO  DistriOptimizer$:408 - [Epoch 1 8192/60000][Iteration 32][Wall Clock 5.877696381s] Trained 256 records in 0.13551165 seconds. Throughput is 1889.1365 records/second. Loss is 2.2909732. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009938382031405287. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:31 INFO  DistriOptimizer$:408 - [Epoch 1 8448/60000][Iteration 33][Wall Clock 6.003853836s] Trained 256 records in 0.126157455 seconds. Throughput is 2029.2103 records/second. Loss is 2.311259. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009936406995230525. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:31 INFO  DistriOptimizer$:408 - [Epoch 1 8704/60000][Iteration 34][Wall Clock 6.120515536s] Trained 256 records in 0.1166617 seconds. Throughput is 2194.3792 records/second. Loss is 2.3026557. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009934432743890324. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:31 INFO  DistriOptimizer$:408 - [Epoch 1 8960/60000][Iteration 35][Wall Clock 6.259747367s] Trained 256 records in 0.139231831 seconds. Throughput is 1838.66 records/second. Loss is 2.2965658. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009932459276916966. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:31 INFO  DistriOptimizer$:408 - [Epoch 1 9216/60000][Iteration 36][Wall Clock 6.425339916s] Trained 256 records in 0.165592549 seconds. Throughput is 1545.9633 records/second. Loss is 2.2874765. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.0099304865938431. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:32 INFO  DistriOptimizer$:408 - [Epoch 1 9472/60000][Iteration 37][Wall Clock 6.553259335s] Trained 256 records in 0.127919419 seconds. Throughput is 2001.2599 records/second. Loss is 2.288213. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009928514694201746. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:32 INFO  DistriOptimizer$:408 - [Epoch 1 9728/60000][Iteration 38][Wall Clock 6.669697337s] Trained 256 records in 0.116438002 seconds. Throughput is 2198.595 records/second. Loss is 2.3025029. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009926543577526304. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:32 INFO  DistriOptimizer$:408 - [Epoch 1 9984/60000][Iteration 39][Wall Clock 6.794344178s] Trained 256 records in 0.124646841 seconds. Throughput is 2053.8025 records/second. Loss is 2.2882657. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009924573243350535. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:32 INFO  DistriOptimizer$:408 - [Epoch 1 10240/60000][Iteration 40][Wall Clock 6.915140743s] Trained 256 records in 0.120796565 seconds. Throughput is 2119.2654 records/second. Loss is 2.2890697. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009922603691208573. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:32 INFO  DistriOptimizer$:408 - [Epoch 1 10496/60000][Iteration 41][Wall Clock 7.090914733s] Trained 256 records in 0.17577399 seconds. Throughput is 1456.4156 records/second. Loss is 2.289593. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.00992063492063492. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:32 INFO  DistriOptimizer$:408 - [Epoch 1 10752/60000][Iteration 42][Wall Clock 7.208216402s] Trained 256 records in 0.117301669 seconds. Throughput is 2182.407 records/second. Loss is 2.288748. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009918666931164452. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:32 INFO  DistriOptimizer$:408 - [Epoch 1 11008/60000][Iteration 43][Wall Clock 7.326266622s] Trained 256 records in 0.11805022 seconds. Throughput is 2168.5686 records/second. Loss is 2.2777138. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009916699722332408. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:33 INFO  DistriOptimizer$:408 - [Epoch 1 11264/60000][Iteration 44][Wall Clock 7.44088561s] Trained 256 records in 0.114618988 seconds. Throughput is 2233.4868 records/second. Loss is 2.2836447. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009914733293674401. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:33 INFO  DistriOptimizer$:408 - [Epoch 1 11520/60000][Iteration 45][Wall Clock 7.554881985s] Trained 256 records in 0.113996375 seconds. Throughput is 2245.6855 records/second. Loss is 2.2883432. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009912767644726409. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:33 INFO  DistriOptimizer$:408 - [Epoch 1 11776/60000][Iteration 46][Wall Clock 7.701815721s] Trained 256 records in 0.146933736 seconds. Throughput is 1742.282 records/second. Loss is 2.2916062. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009910802775024779. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:33 INFO  DistriOptimizer$:408 - [Epoch 1 12032/60000][Iteration 47][Wall Clock 7.82458345s] Trained 256 records in 0.122767729 seconds. Throughput is 2085.2385 records/second. Loss is 2.2839131. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009908838684106223. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:33 INFO  DistriOptimizer$:408 - [Epoch 1 12288/60000][Iteration 48][Wall Clock 7.933700562s] Trained 256 records in 0.109117112 seconds. Throughput is 2346.103 records/second. Loss is 2.2895775. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009906875371507825. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:33 INFO  DistriOptimizer$:408 - [Epoch 1 12544/60000][Iteration 49][Wall Clock 8.052954065s] Trained 256 records in 0.119253503 seconds. Throughput is 2146.6875 records/second. Loss is 2.2775803. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009904912836767036. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:33 INFO  DistriOptimizer$:408 - [Epoch 1 12800/60000][Iteration 50][Wall Clock 8.161121791s] Trained 256 records in 0.108167726 seconds. Throughput is 2366.6948 records/second. Loss is 2.2763772. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009902951079421667. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:33 INFO  DistriOptimizer$:408 - [Epoch 1 13056/60000][Iteration 51][Wall Clock 8.312335619s] Trained 256 records in 0.151213828 seconds. Throughput is 1692.9669 records/second. Loss is 2.2805707. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009900990099009901. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:34 INFO  DistriOptimizer$:408 - [Epoch 1 13312/60000][Iteration 52][Wall Clock 8.429205905s] Trained 256 records in 0.116870286 seconds. Throughput is 2190.4626 records/second. Loss is 2.2768059. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009899029895070284. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:34 INFO  DistriOptimizer$:408 - [Epoch 1 13568/60000][Iteration 53][Wall Clock 8.541208419s] Trained 256 records in 0.112002514 seconds. Throughput is 2285.663 records/second. Loss is 2.2760084. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009897070467141727. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:34 INFO  DistriOptimizer$:408 - [Epoch 1 13824/60000][Iteration 54][Wall Clock 8.657246001s] Trained 256 records in 0.116037582 seconds. Throughput is 2206.1816 records/second. Loss is 2.2810903. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009895111814763508. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:34 INFO  DistriOptimizer$:408 - [Epoch 1 14080/60000][Iteration 55][Wall Clock 8.762589281s] Trained 256 records in 0.10534328 seconds. Throughput is 2430.1501 records/second. Loss is 2.2808795. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009893153937475268. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:34 INFO  DistriOptimizer$:408 - [Epoch 1 14336/60000][Iteration 56][Wall Clock 8.915369896s] Trained 256 records in 0.152780615 seconds. Throughput is 1675.6052 records/second. Loss is 2.2799802. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009891196834817014. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:34 INFO  DistriOptimizer$:408 - [Epoch 1 14592/60000][Iteration 57][Wall Clock 9.034749202s] Trained 256 records in 0.119379306 seconds. Throughput is 2144.4253 records/second. Loss is 2.2710989. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009889240506329113. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:34 INFO  DistriOptimizer$:408 - [Epoch 1 14848/60000][Iteration 58][Wall Clock 9.163826332s] Trained 256 records in 0.12907713 seconds. Throughput is 1983.3102 records/second. Loss is 2.272585. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009887284951552304. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:34 INFO  DistriOptimizer$:408 - [Epoch 1 15104/60000][Iteration 59][Wall Clock 9.273079459s] Trained 256 records in 0.109253127 seconds. Throughput is 2343.1824 records/second. Loss is 2.2660158. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009885330170027679. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:34 INFO  DistriOptimizer$:408 - [Epoch 1 15360/60000][Iteration 60][Wall Clock 9.386129833s] Trained 256 records in 0.113050374 seconds. Throughput is 2264.4773 records/second. Loss is 2.279375. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.0098833761612967. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:35 INFO  DistriOptimizer$:408 - [Epoch 1 15616/60000][Iteration 61][Wall Clock 9.530652542s] Trained 256 records in 0.144522709 seconds. Throughput is 1771.3479 records/second. Loss is 2.256371. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009881422924901186. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:35 INFO  DistriOptimizer$:408 - [Epoch 1 15872/60000][Iteration 62][Wall Clock 9.645063513s] Trained 256 records in 0.114410971 seconds. Throughput is 2237.5476 records/second. Loss is 2.26655. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009879470460383323. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:35 INFO  DistriOptimizer$:408 - [Epoch 1 16128/60000][Iteration 63][Wall Clock 9.750630934s] Trained 256 records in 0.105567421 seconds. Throughput is 2424.9907 records/second. Loss is 2.2634332. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009877518767285659. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:35 INFO  DistriOptimizer$:408 - [Epoch 1 16384/60000][Iteration 64][Wall Clock 9.876443973s] Trained 256 records in 0.125813039 seconds. Throughput is 2034.7653 records/second. Loss is 2.2640436. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009875567845151097. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:35 INFO  DistriOptimizer$:408 - [Epoch 1 16640/60000][Iteration 65][Wall Clock 10.005174076s] Trained 256 records in 0.128730103 seconds. Throughput is 1988.6569 records/second. Loss is 2.2589557. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009873617693522907. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:35 INFO  DistriOptimizer$:408 - [Epoch 1 16896/60000][Iteration 66][Wall Clock 10.145379851s] Trained 256 records in 0.140205775 seconds. Throughput is 1825.8877 records/second. Loss is 2.266001. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.00987166831194472. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:35 INFO  DistriOptimizer$:408 - [Epoch 1 17152/60000][Iteration 67][Wall Clock 10.261057538s] Trained 256 records in 0.115677687 seconds. Throughput is 2213.0457 records/second. Loss is 2.256475. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.00986971969996052. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:35 INFO  DistriOptimizer$:408 - [Epoch 1 17408/60000][Iteration 68][Wall Clock 10.360840744s] Trained 256 records in 0.099783206 seconds. Throughput is 2565.562 records/second. Loss is 2.2599068. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009867771857114663. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:36 INFO  DistriOptimizer$:408 - [Epoch 1 17664/60000][Iteration 69][Wall Clock 10.468792551s] Trained 256 records in 0.107951807 seconds. Throughput is 2371.4287 records/second. Loss is 2.2680082. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009865824782951855. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:36 INFO  DistriOptimizer$:408 - [Epoch 1 17920/60000][Iteration 70][Wall Clock 10.577121209s] Trained 256 records in 0.108328658 seconds. Throughput is 2363.179 records/second. Loss is 2.2597857. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009863878477017163. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:36 INFO  DistriOptimizer$:408 - [Epoch 1 18176/60000][Iteration 71][Wall Clock 10.70974164s] Trained 256 records in 0.132620431 seconds. Throughput is 1930.321 records/second. Loss is 2.2575202. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009861932938856016. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:36 INFO  DistriOptimizer$:408 - [Epoch 1 18432/60000][Iteration 72][Wall Clock 10.820808266s] Trained 256 records in 0.111066626 seconds. Throughput is 2304.9229 records/second. Loss is 2.2486017. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009859988168014198. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:36 INFO  DistriOptimizer$:408 - [Epoch 1 18688/60000][Iteration 73][Wall Clock 10.932673469s] Trained 256 records in 0.111865203 seconds. Throughput is 2288.4685 records/second. Loss is 2.256863. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009858044164037856. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:36 INFO  DistriOptimizer$:408 - [Epoch 1 18944/60000][Iteration 74][Wall Clock 11.029949108s] Trained 256 records in 0.097275639 seconds. Throughput is 2631.697 records/second. Loss is 2.2437444. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009856100926473488. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:36 INFO  DistriOptimizer$:408 - [Epoch 1 19200/60000][Iteration 75][Wall Clock 11.158098301s] Trained 256 records in 0.128149193 seconds. Throughput is 1997.6715 records/second. Loss is 2.2547622. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009854158454867956. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:36 INFO  DistriOptimizer$:408 - [Epoch 1 19456/60000][Iteration 76][Wall Clock 11.281692001s] Trained 256 records in 0.1235937 seconds. Throughput is 2071.303 records/second. Loss is 2.2516446. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009852216748768475. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:36 INFO  DistriOptimizer$:408 - [Epoch 1 19712/60000][Iteration 77][Wall Clock 11.392112126s] Trained 256 records in 0.110420125 seconds. Throughput is 2318.418 records/second. Loss is 2.249304. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009850275807722615. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:37 INFO  DistriOptimizer$:408 - [Epoch 1 19968/60000][Iteration 78][Wall Clock 11.497932893s] Trained 256 records in 0.105820767 seconds. Throughput is 2419.1848 records/second. Loss is 2.251779. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009848335631278314. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:37 INFO  DistriOptimizer$:408 - [Epoch 1 20224/60000][Iteration 79][Wall Clock 11.594257624s] Trained 256 records in 0.096324731 seconds. Throughput is 2657.6768 records/second. Loss is 2.247321. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009846396218983852. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:37 INFO  DistriOptimizer$:408 - [Epoch 1 20480/60000][Iteration 80][Wall Clock 11.703408412s] Trained 256 records in 0.109150788 seconds. Throughput is 2345.3794 records/second. Loss is 2.2537298. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009844457570387872. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:37 INFO  DistriOptimizer$:408 - [Epoch 1 20736/60000][Iteration 81][Wall Clock 11.83951646s] Trained 256 records in 0.136108048 seconds. Throughput is 1880.8588 records/second. Loss is 2.240064. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.00984251968503937. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:37 INFO  DistriOptimizer$:408 - [Epoch 1 20992/60000][Iteration 82][Wall Clock 11.935406123s] Trained 256 records in 0.095889663 seconds. Throughput is 2669.735 records/second. Loss is 2.2434292. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.0098405825624877. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:37 INFO  DistriOptimizer$:408 - [Epoch 1 21248/60000][Iteration 83][Wall Clock 12.034715572s] Trained 256 records in 0.099309449 seconds. Throughput is 2577.801 records/second. Loss is 2.245399. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009838646202282567. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:37 INFO  DistriOptimizer$:408 - [Epoch 1 21504/60000][Iteration 84][Wall Clock 12.143456026s] Trained 256 records in 0.108740454 seconds. Throughput is 2354.2295 records/second. Loss is 2.2370453. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009836710603974032. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:37 INFO  DistriOptimizer$:408 - [Epoch 1 21760/60000][Iteration 85][Wall Clock 12.24297504s] Trained 256 records in 0.099519014 seconds. Throughput is 2572.3728 records/second. Loss is 2.2326634. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009834775767112511. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:37 INFO  DistriOptimizer$:408 - [Epoch 1 22016/60000][Iteration 86][Wall Clock 12.368700302s] Trained 256 records in 0.125725262 seconds. Throughput is 2036.1858 records/second. Loss is 2.2467537. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009832841691248772. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:38 INFO  DistriOptimizer$:408 - [Epoch 1 22272/60000][Iteration 87][Wall Clock 12.459523369s] Trained 256 records in 0.090823067 seconds. Throughput is 2818.6672 records/second. Loss is 2.2357323. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009830908375933936. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:38 INFO  DistriOptimizer$:408 - [Epoch 1 22528/60000][Iteration 88][Wall Clock 12.563353842s] Trained 256 records in 0.103830473 seconds. Throughput is 2465.5576 records/second. Loss is 2.2404912. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.00982897582071948. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:38 INFO  DistriOptimizer$:408 - [Epoch 1 22784/60000][Iteration 89][Wall Clock 12.668920303s] Trained 256 records in 0.105566461 seconds. Throughput is 2425.0125 records/second. Loss is 2.234549. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009827044025157232. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:38 INFO  DistriOptimizer$:408 - [Epoch 1 23040/60000][Iteration 90][Wall Clock 12.777470652s] Trained 256 records in 0.108550349 seconds. Throughput is 2358.3525 records/second. Loss is 2.2366357. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009825112988799371. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:38 INFO  DistriOptimizer$:408 - [Epoch 1 23296/60000][Iteration 91][Wall Clock 12.898415244s] Trained 256 records in 0.120944592 seconds. Throughput is 2116.6719 records/second. Loss is 2.230674. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009823182711198428. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:38 INFO  DistriOptimizer$:408 - [Epoch 1 23552/60000][Iteration 92][Wall Clock 12.994186835s] Trained 256 records in 0.095771591 seconds. Throughput is 2673.0266 records/second. Loss is 2.231901. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009821253191907287. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:38 INFO  DistriOptimizer$:408 - [Epoch 1 23808/60000][Iteration 93][Wall Clock 13.096501006s] Trained 256 records in 0.102314171 seconds. Throughput is 2502.0972 records/second. Loss is 2.2302618. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009819324430479184. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:38 INFO  DistriOptimizer$:408 - [Epoch 1 24064/60000][Iteration 94][Wall Clock 13.202479738s] Trained 256 records in 0.105978732 seconds. Throughput is 2415.5789 records/second. Loss is 2.2225537. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009817396426467702. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:38 INFO  DistriOptimizer$:408 - [Epoch 1 24320/60000][Iteration 95][Wall Clock 13.315308799s] Trained 256 records in 0.112829061 seconds. Throughput is 2268.919 records/second. Loss is 2.2294123. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009815469179426778. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:39 INFO  DistriOptimizer$:408 - [Epoch 1 24576/60000][Iteration 96][Wall Clock 13.431155753s] Trained 256 records in 0.115846954 seconds. Throughput is 2209.812 records/second. Loss is 2.2230783. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009813542688910697. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:39 INFO  DistriOptimizer$:408 - [Epoch 1 24832/60000][Iteration 97][Wall Clock 13.542605677s] Trained 256 records in 0.111449924 seconds. Throughput is 2296.9956 records/second. Loss is 2.227509. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009811616954474096. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:39 INFO  DistriOptimizer$:408 - [Epoch 1 25088/60000][Iteration 98][Wall Clock 13.643333663s] Trained 256 records in 0.100727986 seconds. Throughput is 2541.4983 records/second. Loss is 2.2239668. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009809691975671964. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:39 INFO  DistriOptimizer$:408 - [Epoch 1 25344/60000][Iteration 99][Wall Clock 13.761719084s] Trained 256 records in 0.118385421 seconds. Throughput is 2162.4285 records/second. Loss is 2.2182283. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.00980776775205963. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:39 INFO  DistriOptimizer$:408 - [Epoch 1 25600/60000][Iteration 100][Wall Clock 13.854713278s] Trained 256 records in 0.092994194 seconds. Throughput is 2752.86 records/second. Loss is 2.2239351. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009805844283192783. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:39 INFO  DistriOptimizer$:408 - [Epoch 1 25856/60000][Iteration 101][Wall Clock 13.988447422s] Trained 256 records in 0.133734144 seconds. Throughput is 1914.2457 records/second. Loss is 2.214092. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.00980392156862745. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:39 INFO  DistriOptimizer$:408 - [Epoch 1 26112/60000][Iteration 102][Wall Clock 14.098765203s] Trained 256 records in 0.110317781 seconds. Throughput is 2320.5688 records/second. Loss is 2.2198634. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009801999607920015. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:39 INFO  DistriOptimizer$:408 - [Epoch 1 26368/60000][Iteration 103][Wall Clock 14.20665348s] Trained 256 records in 0.107888277 seconds. Throughput is 2372.825 records/second. Loss is 2.2193031. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009800078400627205. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:39 INFO  DistriOptimizer$:408 - [Epoch 1 26624/60000][Iteration 104][Wall Clock 14.303698974s] Trained 256 records in 0.097045494 seconds. Throughput is 2637.938 records/second. Loss is 2.2106214. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009798157946306094. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:40 INFO  DistriOptimizer$:408 - [Epoch 1 26880/60000][Iteration 105][Wall Clock 14.399804559s] Trained 256 records in 0.096105585 seconds. Throughput is 2663.737 records/second. Loss is 2.217881. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009796238244514107. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:40 INFO  DistriOptimizer$:408 - [Epoch 1 27136/60000][Iteration 106][Wall Clock 14.508794468s] Trained 256 records in 0.108989909 seconds. Throughput is 2348.8413 records/second. Loss is 2.2126822. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009794319294809012. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:40 INFO  DistriOptimizer$:408 - [Epoch 1 27392/60000][Iteration 107][Wall Clock 14.613100093s] Trained 256 records in 0.104305625 seconds. Throughput is 2454.326 records/second. Loss is 2.2115948. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009792401096748922. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:40 INFO  DistriOptimizer$:408 - [Epoch 1 27648/60000][Iteration 108][Wall Clock 14.716106325s] Trained 256 records in 0.103006232 seconds. Throughput is 2485.2866 records/second. Loss is 2.2038746. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009790483649892304. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:40 INFO  DistriOptimizer$:408 - [Epoch 1 27904/60000][Iteration 109][Wall Clock 14.814681818s] Trained 256 records in 0.098575493 seconds. Throughput is 2596.9944 records/second. Loss is 2.2118363. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009788566953797963. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:40 INFO  DistriOptimizer$:408 - [Epoch 1 28160/60000][Iteration 110][Wall Clock 14.92287154s] Trained 256 records in 0.108189722 seconds. Throughput is 2366.2136 records/second. Loss is 2.2112231. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009786651008025053. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:40 INFO  DistriOptimizer$:408 - [Epoch 1 28416/60000][Iteration 111][Wall Clock 15.041401287s] Trained 256 records in 0.118529747 seconds. Throughput is 2159.7954 records/second. Loss is 2.208816. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009784735812133072. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:40 INFO  DistriOptimizer$:408 - [Epoch 1 28672/60000][Iteration 112][Wall Clock 15.133078263s] Trained 256 records in 0.091676976 seconds. Throughput is 2792.4133 records/second. Loss is 2.204679. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009782821365681862. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:40 INFO  DistriOptimizer$:408 - [Epoch 1 28928/60000][Iteration 113][Wall Clock 15.228512804s] Trained 256 records in 0.095434541 seconds. Throughput is 2682.467 records/second. Loss is 2.2017653. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009780907668231613. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:40 INFO  DistriOptimizer$:408 - [Epoch 1 29184/60000][Iteration 114][Wall Clock 15.345917632s] Trained 256 records in 0.117404828 seconds. Throughput is 2180.4895 records/second. Loss is 2.2062812. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009778994719342852. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:41 INFO  DistriOptimizer$:408 - [Epoch 1 29440/60000][Iteration 115][Wall Clock 15.443454395s] Trained 256 records in 0.097536763 seconds. Throughput is 2624.6514 records/second. Loss is 2.1947405. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009777082518576457. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:41 INFO  DistriOptimizer$:408 - [Epoch 1 29696/60000][Iteration 116][Wall Clock 15.576023804s] Trained 256 records in 0.132569409 seconds. Throughput is 1931.064 records/second. Loss is 2.1982944. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009775171065493648. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:41 INFO  DistriOptimizer$:408 - [Epoch 1 29952/60000][Iteration 117][Wall Clock 15.68460386s] Trained 256 records in 0.108580056 seconds. Throughput is 2357.7075 records/second. Loss is 2.1975932. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009773260359655981. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:41 INFO  DistriOptimizer$:408 - [Epoch 1 30208/60000][Iteration 118][Wall Clock 15.787408376s] Trained 256 records in 0.102804516 seconds. Throughput is 2490.1628 records/second. Loss is 2.1868808. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009771350400625366. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:41 INFO  DistriOptimizer$:408 - [Epoch 1 30464/60000][Iteration 119][Wall Clock 15.889029632s] Trained 256 records in 0.101621256 seconds. Throughput is 2519.158 records/second. Loss is 2.1782966. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009769441187964047. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:41 INFO  DistriOptimizer$:408 - [Epoch 1 30720/60000][Iteration 120][Wall Clock 15.993245543s] Trained 256 records in 0.104215911 seconds. Throughput is 2456.4387 records/second. Loss is 2.1785767. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009767532721234616. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:41 INFO  DistriOptimizer$:408 - [Epoch 1 30976/60000][Iteration 121][Wall Clock 16.098946316s] Trained 256 records in 0.105700773 seconds. Throughput is 2421.9312 records/second. Loss is 2.196351. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009765625. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:41 INFO  DistriOptimizer$:408 - [Epoch 1 31232/60000][Iteration 122][Wall Clock 16.218434364s] Trained 256 records in 0.119488048 seconds. Throughput is 2142.4736 records/second. Loss is 2.185234. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009763718023823472. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:41 INFO  DistriOptimizer$:408 - [Epoch 1 31488/60000][Iteration 123][Wall Clock 16.322010204s] Trained 256 records in 0.10357584 seconds. Throughput is 2471.619 records/second. Loss is 2.1842268. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009761811792268645. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:42 INFO  DistriOptimizer$:408 - [Epoch 1 31744/60000][Iteration 124][Wall Clock 16.43184179s] Trained 256 records in 0.109831586 seconds. Throughput is 2330.8413 records/second. Loss is 2.167402. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009759906304899474. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:42 INFO  DistriOptimizer$:408 - [Epoch 1 32000/60000][Iteration 125][Wall Clock 16.534740672s] Trained 256 records in 0.102898882 seconds. Throughput is 2487.8794 records/second. Loss is 2.1802752. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.00975800156128025. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:42 INFO  DistriOptimizer$:408 - [Epoch 1 32256/60000][Iteration 126][Wall Clock 16.667921004s] Trained 256 records in 0.133180332 seconds. Throughput is 1922.2057 records/second. Loss is 2.177803. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009756097560975611. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:42 INFO  DistriOptimizer$:408 - [Epoch 1 32512/60000][Iteration 127][Wall Clock 16.766719171s] Trained 256 records in 0.098798167 seconds. Throughput is 2591.141 records/second. Loss is 2.187051. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009754194303550527. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:42 INFO  DistriOptimizer$:408 - [Epoch 1 32768/60000][Iteration 128][Wall Clock 16.8644236s] Trained 256 records in 0.097704429 seconds. Throughput is 2620.1475 records/second. Loss is 2.1694176. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009752291788570313. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:42 INFO  DistriOptimizer$:408 - [Epoch 1 33024/60000][Iteration 129][Wall Clock 16.963080228s] Trained 256 records in 0.098656628 seconds. Throughput is 2594.8586 records/second. Loss is 2.1697707. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009750390015600624. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:42 INFO  DistriOptimizer$:408 - [Epoch 1 33280/60000][Iteration 130][Wall Clock 17.05761842s] Trained 256 records in 0.094538192 seconds. Throughput is 2707.9004 records/second. Loss is 2.1655269. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009748488984207448. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:42 INFO  DistriOptimizer$:408 - [Epoch 1 33536/60000][Iteration 131][Wall Clock 17.18093555s] Trained 256 records in 0.12331713 seconds. Throughput is 2075.9485 records/second. Loss is 2.167717. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009746588693957114. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:42 INFO  DistriOptimizer$:408 - [Epoch 1 33792/60000][Iteration 132][Wall Clock 17.270560886s] Trained 256 records in 0.089625336 seconds. Throughput is 2856.3352 records/second. Loss is 2.166995. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009744689144416294. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:42 INFO  DistriOptimizer$:408 - [Epoch 1 34048/60000][Iteration 133][Wall Clock 17.357220998s] Trained 256 records in 0.086660112 seconds. Throughput is 2954.0696 records/second. Loss is 2.1579478. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009742790335151987. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:43 INFO  DistriOptimizer$:408 - [Epoch 1 34304/60000][Iteration 134][Wall Clock 17.457570837s] Trained 256 records in 0.100349839 seconds. Throughput is 2551.0754 records/second. Loss is 2.1773996. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009740892265731542. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:43 INFO  DistriOptimizer$:408 - [Epoch 1 34560/60000][Iteration 135][Wall Clock 17.548930633s] Trained 256 records in 0.091359796 seconds. Throughput is 2802.108 records/second. Loss is 2.168469. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009738994935722634. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:43 INFO  DistriOptimizer$:408 - [Epoch 1 34816/60000][Iteration 136][Wall Clock 17.669303849s] Trained 256 records in 0.120373216 seconds. Throughput is 2126.719 records/second. Loss is 2.1643074. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009737098344693282. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:43 INFO  DistriOptimizer$:408 - [Epoch 1 35072/60000][Iteration 137][Wall Clock 17.778814916s] Trained 256 records in 0.109511067 seconds. Throughput is 2337.6633 records/second. Loss is 2.157177. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009735202492211837. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:43 INFO  DistriOptimizer$:408 - [Epoch 1 35328/60000][Iteration 138][Wall Clock 17.882040669s] Trained 256 records in 0.103225753 seconds. Throughput is 2480.0012 records/second. Loss is 2.16. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009733307377846992. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:43 INFO  DistriOptimizer$:408 - [Epoch 1 35584/60000][Iteration 139][Wall Clock 17.974237684s] Trained 256 records in 0.092197015 seconds. Throughput is 2776.6626 records/second. Loss is 2.1516252. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009731413001167769. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:43 INFO  DistriOptimizer$:408 - [Epoch 1 35840/60000][Iteration 140][Wall Clock 18.059233394s] Trained 256 records in 0.08499571 seconds. Throughput is 3011.9167 records/second. Loss is 2.1567023. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.00972951936174353. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:43 INFO  DistriOptimizer$:408 - [Epoch 1 36096/60000][Iteration 141][Wall Clock 18.17914465s] Trained 256 records in 0.119911256 seconds. Throughput is 2134.912 records/second. Loss is 2.1486394. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009727626459143969. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:43 INFO  DistriOptimizer$:408 - [Epoch 1 36352/60000][Iteration 142][Wall Clock 18.273306076s] Trained 256 records in 0.094161426 seconds. Throughput is 2718.7354 records/second. Loss is 2.1586304. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009725734292939117. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:43 INFO  DistriOptimizer$:408 - [Epoch 1 36608/60000][Iteration 143][Wall Clock 18.366972795s] Trained 256 records in 0.093666719 seconds. Throughput is 2733.0947 records/second. Loss is 2.1394603. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009723842862699339. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:44 INFO  DistriOptimizer$:408 - [Epoch 1 36864/60000][Iteration 144][Wall Clock 18.475409037s] Trained 256 records in 0.108436242 seconds. Throughput is 2360.8342 records/second. Loss is 2.132481. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009721952167995334. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:44 INFO  DistriOptimizer$:408 - [Epoch 1 37120/60000][Iteration 145][Wall Clock 18.577633706s] Trained 256 records in 0.102224669 seconds. Throughput is 2504.2878 records/second. Loss is 2.13989. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009720062208398135. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:44 INFO  DistriOptimizer$:408 - [Epoch 1 37376/60000][Iteration 146][Wall Clock 18.696475736s] Trained 256 records in 0.11884203 seconds. Throughput is 2154.12 records/second. Loss is 2.1345727. Sequentialaf538ea6's hyper parameters: Current learning rate is 0.009718172983479108. Current dampening is 1.7976931348623157E308.  
2019-10-17 18:04:44 ERROR DistriOptimizer$:894 - Error: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
java.lang.reflect.Constructor.newInstance(Constructor.java:423)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:238)
py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
py4j.GatewayConnection.run(GatewayConnection.java:238)
java.lang.Thread.run(Thread.java:748)

The currently active SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
java.lang.reflect.Constructor.newInstance(Constructor.java:423)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:238)
py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
py4j.GatewayConnection.run(GatewayConnection.java:238)
java.lang.Thread.run(Thread.java:748)
         
	at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:99)
	at org.apache.spark.SparkContext.broadcast(SparkContext.scala:1479)
	at com.intel.analytics.bigdl.optim.DistriOptimizer$.optimize(DistriOptimizer.scala:359)
	at com.intel.analytics.bigdl.optim.DistriOptimizer.optimize(DistriOptimizer.scala:869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)

2019-10-17 18:04:44 INFO  DistriOptimizer$:908 - Retrying 1 times
